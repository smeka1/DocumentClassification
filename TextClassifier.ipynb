{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names = ['Label','Content']\n",
    "temp = pd.read_csv('orig.csv', names = column_names,header=None,chunksize=1000)\n",
    "df = pd.concat(temp, ignore_index=True)\n",
    "#df_second = df.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for i in range(len(df['Label'])):\n",
    "  if(df['Label'][i].isupper()):\n",
    "    df['category_id'] = df['Label'].factorize()[0]\n",
    "'''    \n",
    "df['category_id'] = df['Label'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_df = df[['Label', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Label']].values)\n",
    "\n",
    "#category_id_df.head(66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62204, 89007)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1')\n",
    "features = tfidf.fit_transform(df.Content.astype('str'))\n",
    "\n",
    "labels = df.category_id\n",
    "joblib.dump(tfidf,'tfidf.pkl')\n",
    "joblib.dump(id_to_category, 'dict.pkl')\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_svc_doc_clf_model.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "model = LinearSVC()\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.22, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "'''conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=category_id_df.Label.values, yticklabels=category_id_df.Label.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "'''\n",
    "joblib.dump(tfidf,'tfidf.pkl')\n",
    "joblib.dump(model, 'linear_svc_doc_clf_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLICY CHANGE\n",
      "RETURNED CHECK\n",
      "BILL\n",
      "CANCELLATION NOTICE\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "POLICY CHANGE\n",
      "BILL\n",
      "CANCELLATION NOTICE\n",
      "BILL\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "CANCELLATION NOTICE\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "DECLARATION\n",
      "CANCELLATION NOTICE\n",
      "POLICY CHANGE\n",
      "CHANGE ENDORSEMENT\n",
      "NON-RENEWAL NOTICE\n",
      "BINDER\n",
      "BINDER\n",
      "POLICY CHANGE\n",
      "CANCELLATION NOTICE\n",
      "BINDER\n",
      "POLICY CHANGE\n",
      "REINSTATEMENT NOTICE\n",
      "BILL\n",
      "BILL\n",
      "REINSTATEMENT NOTICE\n",
      "RETURNED CHECK\n",
      "BILL\n",
      "BINDER\n",
      "DELETION OF INTEREST\n",
      "POLICY CHANGE\n",
      "NON-RENEWAL NOTICE\n",
      "BINDER\n",
      "BINDER\n",
      "REINSTATEMENT NOTICE\n",
      "DELETION OF INTEREST\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "POLICY CHANGE\n",
      "CANCELLATION NOTICE\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "BINDER\n",
      "BILL\n",
      "BILL\n",
      "REINSTATEMENT NOTICE\n",
      "BILL\n",
      "REINSTATEMENT NOTICE\n",
      "BINDER\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "RETURNED CHECK\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "CANCELLATION NOTICE\n",
      "POLICY CHANGE\n",
      "BILL\n",
      "BILL\n",
      "REINSTATEMENT NOTICE\n",
      "BILL\n",
      "BINDER\n",
      "CANCELLATION NOTICE\n",
      "BINDER\n",
      "CANCELLATION NOTICE\n",
      "BINDER\n",
      "EXPIRATION NOTICE\n",
      "DELETION OF INTEREST\n",
      "BILL\n",
      "BILL\n",
      "CANCELLATION NOTICE\n",
      "BILL\n",
      "POLICY CHANGE\n",
      "BINDER\n",
      "NON-RENEWAL NOTICE\n",
      "BILL\n",
      "BINDER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(loaded_model.predict(\"133d46f7ed38 a31962fbd5f3 b61f1af56200 f7bb594ff117 036087ac04f9 b136f6349cf3 a86f2ba617ec f8b0c07e306c eb562127f33e 826d4465f1c0 45238a6f945e 1015893e384a 586242498a88 26f768da5068 b1d2e1729890 6d25574664d2 9cdf4a63deb0 b59e343416f7 7d7400d32c11 737c16de8e55 1ae9623df135 b9699ce57810 8b6c5bb157a9 f0666bdbc8a5 6179f2d9e26e 98d0d51b397c c33578d25a0d a4a4777e23d9 93c988b67c47 9bc96abb24e5 2ef7c27a5df4 25c57acdf805 e67eb757a353 f7ae6f8257da 069ffcd62e52 87b8193a0183 fe081ae57a8b ce1f034abb5d 1c303d15eb65 4ea63014c7a0 565cc562d4a1 c337a85b8ef9 f7ae6f8257da 9bc65adc033c 580a08f5c8b9 80ccae569db6 eeb86a6a04e4 98d0d51b397c aba93ec140b0 52c54f67c943 b74586333c1d 8b6c5bb157a9 5be0eb55194f c33578d25a0d 5f9c2ac954be 46c88d9303da e5e6da4eb92e b9a9bc5cc136 943a2ce588ec 7d9e333a86da b9699ce57810be9f9e5522c9 0562c756a2f2 b811dd4432bc 1f97a7936c3a 8b6c5bb157a9 2416c9a61125 14571c343a32 9bc65adc033c c59201b32e7a18f413d06b26 34d42b678642 1068682ce752 9371e8fd12aa 508228b8bcd4 0c75f07ae50d ea51fa83c91c 9a6cf3c658f9 72bd4a50cf4a 6da44f4867c0 9a6cf3c658f9 eeb86a6a04e4 6b304aabdcee 8d21095e8690 649cadc13088 5fa62998872f be9f9e5522c9 0562c756a2f2 b811dd4432bc 3304492deeec f3ecb214bd90 5acedb3f068f 1f97a7936c3a 8b6c5bb157a9 2416c9a61125\"))\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.externals import joblib\n",
    "    \n",
    "    column_names = ['Content']\n",
    "    temp = pd.read_csv('test100.csv', names = column_names,header=None,chunksize=1000)\n",
    "    df = pd.concat(temp, ignore_index=True)\n",
    "    \n",
    "    vect = joblib.load('tfidf.pkl')\n",
    "    dict = joblib.load('dict.pkl')\n",
    "    #feature_list = vect.get_feature_names()\n",
    "    loaded_model = joblib.load('linear_svc_doc_clf_model.pkl')\n",
    "    #indices = np.argsort(loaded_model.coef_['category_id'])\n",
    "    text = tfidf.transform(df['Content'])\n",
    "    i =1\n",
    "    predicted_IDs = loaded_model.predict(text)\n",
    "    for ID in predicted_IDs:\n",
    "        print(dict[ID])\n",
    "    \n",
    "def main():\n",
    "    predict()\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    main()\n",
    "    \n",
    "'''\n",
    "print(loaded_model.predict(\"133d46f7ed38 a31962fbd5f3 b61f1af56200 f7bb594ff117 036087ac04f9 b136f6349cf3 a86f2ba617ec \\\n",
    "f8b0c07e306c eb562127f33e 826d4465f1c0 45238a6f945e 1015893e384a 586242498a88 26f768da5068 b1d2e1729890 6d25574664d2 \\\n",
    "9cdf4a63deb0 b59e343416f7 7d7400d32c11 737c16de8e55 1ae9623df135 b9699ce57810 8b6c5bb157a9 f0666bdbc8a5 6179f2d9e26e \\\n",
    "98d0d51b397c c33578d25a0d a4a4777e23d9 93c988b67c47 9bc96abb24e5 2ef7c27a5df4 25c57acdf805 e67eb757a353 f7ae6f8257da \\\n",
    "069ffcd62e52 87b8193a0183 fe081ae57a8b ce1f034abb5d 1c303d15eb65 4ea63014c7a0 565cc562d4a1 c337a85b8ef9 f7ae6f8257da \\\n",
    "9bc65adc033c 580a08f5c8b9 80ccae569db6 eeb86a6a04e4 98d0d51b397c aba93ec140b0 52c54f67c943 b74586333c1d 8b6c5bb157a9 \\\n",
    "5be0eb55194f c33578d25a0d 5f9c2ac954be 46c88d9303da e5e6da4eb92e b9a9bc5cc136 943a2ce588ec 7d9e333a86da b9699ce57810\\\n",
    "be9f9e5522c9 0562c756a2f2 b811dd4432bc 1f97a7936c3a 8b6c5bb157a9 2416c9a61125 14571c343a32 9bc65adc033c c59201b32e7a\\\n",
    "18f413d06b26 34d42b678642 1068682ce752 9371e8fd12aa 508228b8bcd4 0c75f07ae50d ea51fa83c91c 9a6cf3c658f9 72bd4a50cf4a \\\n",
    "6da44f4867c0 9a6cf3c658f9 eeb86a6a04e4 6b304aabdcee 8d21095e8690 649cadc13088 5fa62998872f be9f9e5522c9 0562c756a2f2 \\\n",
    "b811dd4432bc 3304492deeec f3ecb214bd90 5acedb3f068f 1f97a7936c3a 8b6c5bb157a9 2416c9a61125\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 5\n",
    "for Label, category_id in sorted(category_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == category_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  #print(\"# '{}':\".format(Label))\n",
    "  #print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "'''from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "'''\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Content'], df['Label'], random_state = 0)\n",
    "#count_vect = CountVectorizer()\n",
    "logistic_reg_model = LogisticRegression()\n",
    "CV=5\n",
    "cv_df = pd.DataFrame(index=range(CV))\n",
    "entries = []\n",
    "models = [\n",
    "#   RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    LogisticRegression(random_state=0)]\n",
    "\n",
    "for model in models:\n",
    "   model_name = model.__class__.__name__\n",
    "   accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=5)\n",
    "   for fold_idx, accuracy in enumerate(accuracies):\n",
    "      entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "cv_df.groupby('model_name').accuracy.mean()\n",
    "\n",
    "#logistic_reg_model.fit(X_train, y_train)\n",
    "\n",
    "#X_train_counts = count_vect.fit_transform(X_train.astype(str))\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "#clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=5)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "cv_df.groupby('model_name').accuracy.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 240\n",
    "correct = 0\n",
    "print(start)\n",
    "while(start < 260):\n",
    "    print(clf.predict(count_vect.transform(df['Content'][start] )) )\n",
    "    start+=1\n",
    "#    if(df['Label'][start] == clf.predict(count_vect.transform(df['Content'][start] ))):\n",
    "#        correct +=1\n",
    "#        start+=1\n",
    "            \n",
    "#print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
